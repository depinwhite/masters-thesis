\newpage

\subsection{Предлагаемый подход}

На вход модели GECToR подается предложение, которое требуется исправить. Далее предложение разбивается на последовательность токенов. Таким образом, задача исправления грамматических ошибок сводится к нахождению отображения \( T \) для сопоставления каждого токена с соответствующим правилом из словаря корректирующих правил. Для русского языка построен словарь, состоящий из 5183 правил, которые будут подробно описаны ниже.

Данная постановка задачи имеет недостаток: каждый токен сопоставляется только с одним правилом из словаря, но иногда для исправления ошибки требуется большее количество изменений. Для решения данной проблемы предлагается использовать итеративное исправление: предложение, полученное в результате работы модели, снова подается модели на вход. Таким образом, модель предсказывает правила для новой последовательности токенов. Правила разработаны таким образом, что последовательность токенов с ошибками может быть преобразована в последовательность токенов без ошибок за конечное число итераций. Проделаны следующие адаптации модели GECToR для русского языка:


\begin{enumerate}
    \item Проведено обучение модели RUGECToR в два этапа:
    \begin{enumerate}
        \item обучение на синтетических данных с ошибками;
        \item дообучение на комбинации из синтетических данных с ошибками и без ошибок;
    \end{enumerate}
    
    \item Изменен этап применения модели для исправления ошибок с использованием библиотеки pymorphy2~\cite{b23};
    
    \item Составлен словарь правил для исправления ошибок;
    
    \item В качестве кодировщика использован Multilingual BERT.

    
\end{enumerate}