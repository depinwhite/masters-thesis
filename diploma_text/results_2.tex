\subsection{Результаты}


Как показано в таблице~\ref{tab:result}, результаты были получены на наборах данных CoNLL-2014 (тест) и BEA-2019 (тест) с использованием соответствующих метрик --- $M^{2}$-scorer и ERRANT. 

На наборе данных CoNLL-2014 наша модель на уровне подслов показывает конкурентоспособный результат $F_{0.5} = 62.4$ по сравнению с $F_{0.5} = 65.3$ для модели на уровне слов из работы~\cite{b15}. Более того, наша модель на уровне подслов немного превосходит оригинальную модель по метрике полноты: $R = 40.4$ против $R = 40.1$.

На наборе данных BEA-2019 наша модель не смогла приблизиться к результатам оригинальной модели, однако всё ещё демонстрирует достаточно высокий показатель $F_{0.5} = 61.9$. Как видно, модель показывает относительно низкую полноту, что можно объяснить тем, что был использован не весь синтетический корпус данных. 

Тем не менее, было показано достижение сравнимых результатов, используя обучение без учителя. Важно отметить, что данный подход является независимым и может быть адаптирован к любому языку с использованием словаря на уровне подслов.
